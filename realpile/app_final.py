import streamlit as st
import cv2
import time
import threading

import cv2
import mediapipe as mp
import time
import numpy as np
import joblib

import matplotlib
matplotlib.use('TkAgg')     # OpenCV ì¶©ëŒ ë°©ì§€
import matplotlib.pyplot as plt

# -------------------------------
# í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
# -------------------------------
try:
    MODEL_FILE = "./DAiSEE/models/focus_model.pkl"
    if 'model' not in st.session_state:
        st.session_state['model'] = joblib.load(MODEL_FILE)
except FileNotFoundError:
    st.error(f"ëª¨ë¸ íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {MODEL_FILE}")
    st.session_state['model'] = None

# -------------------------------
# Mediapipe ì´ˆê¸°í™”
# -------------------------------
mp_holistic = mp.solutions.holistic

# -------------------------------
# ë¯¼ê°ë„ ê¸°ì¤€ ì„¤ì •
# -------------------------------
CLOSED_THRESHOLD = 3         # ëˆˆ ì™„ì „íˆ ê°ê¹€ ê¸°ì¤€
HALF_CLOSED_THRESHOLD = 6    # ëˆˆ ë°˜ê°ê¹€ ê¸°ì¤€
YAWN_THRESHOLD = 25          # í•˜í’ˆ ê¸°ì¤€
GAZE_THRESHOLD = 0.45        # ì‹œì„  ì´íƒˆ ê¸°ì¤€
BLINK_MAX = 20               # ìµœëŒ€ ê¹œë¹¡ì„ ìˆ˜



# -------------------------------
# streamlit ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
# ------------------------------- 
if 'recording' not in st.session_state:
    st.session_state['recording'] = False
if 'recording_thread' not in st.session_state:
    st.session_state['recording_thread'] = None
if 'stop_flag' not in st.session_state:
    st.session_state['stop_flag'] = threading.Event()
if 'cap' not in st.session_state:
    st.session_state['cap'] = None

# -------------------------------
# ì¸¡ì • ë³€ìˆ˜ ì´ˆê¸°í™”
# ------------------------------- 
if 'all_scores' not in st.session_state:
    st.session_state['all_scores'] = []
if 'all_states' not in st.session_state:
    st.session_state['all_states'] = []

if 'segment_start' not in st.session_state:
    st.session_state['segment_start'] = time.time()
if 'blink_count' not in st.session_state:
    st.session_state['blink_count'] = 0
if 'yawn_count' not in st.session_state:
    st.session_state['yawn_count'] = 0
if 'closed_seconds' not in st.session_state:
    st.session_state['closed_seconds'] = 0
if 'half_closed_seconds' not in st.session_state:
    st.session_state['half_closed_seconds'] = 0
if 'gaze_out_seconds' not in st.session_state:
    st.session_state['gaze_out_seconds'] = 0
if 'eye_closed' not in st.session_state:
    st.session_state['eye_closed'] = False
if 'yawn_state' not in st.session_state:
    st.session_state['yawn_state'] = False
if 'analysis' not in st.session_state: # ìµœì¢… ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ê³µê°„
    st.session_state['analysis'] = None

# -------------------------------
# ì§‘ì¤‘ë„ ê³„ì‚° í•¨ìˆ˜
# -------------------------------
def calculate_focus(yawn, blink, closed_time, half_closed_time, gaze_out_time,
                    w1=0.3, w2=0.2, w3=0.3, w4=0.2):
    """
    ê° í–‰ë™ë³„ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•´ íŒ¨ë„í‹° ê³„ì‚° í›„ 100ì—ì„œ ì°¨ê°
    """
    penalty = 100 * (w1*yawn + w2*(blink/BLINK_MAX) + w3*(closed_time/10) + w4*(gaze_out_time/10))
    score = 100 - penalty
    return max(0, score)

# -------------------------------
# ì§‘ì¤‘ë„ ì €í•˜ ì´ìœ  ë¶„ì„
# -------------------------------
def analyze_focus_reason(blink, yawn, closed, half_closed, gaze):
    """
    í‰ê· ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ë†’ì€ íŒ¨ë„í‹° í•­ëª©ì„ ì›ì¸ìœ¼ë¡œ íŒë‹¨
    """
    penalties = {
        'blink': blink * 0.2,
        'yawn': yawn * 0.3,
        'closed': closed * 0.3,
        'half_closed': half_closed * 0.1,
        'gaze_out': gaze * 0.2
    }
    reason = max(penalties, key=penalties.get)
    return reason, penalties

# -------------------------------
# í‰ê·  ì§‘ì¤‘ë„ ê³„ì‚° ë° ë‚®ì€ ì›ì¸ ë¶„ì„
# -------------------------------
def analysis():
    all_scores = st.session_state['all_score']
    all_states = st.session_state['all_states']

    avg_focus = round(sum(all_scores)/len(all_scores), 2)

    avg_blink = sum(s['blink_count'] for s in all_states)/len(all_states)
    avg_yawn = sum(s['yawn_count'] for s in all_states)/len(all_states)
    avg_closed = sum(s['closed_seconds'] for s in all_states)/len(all_states)
    avg_half_closed = sum(s['half_closed_seconds'] for s in all_states)/len(all_states)
    avg_gaze = sum(s['gaze_out_seconds'] for s in all_states)/len(all_states)

    reason, penalties = analyze_focus_reason(avg_blink, avg_yawn, avg_closed, avg_half_closed, avg_gaze)

    st.session_state['analysis'] = {
        'avg_focus': avg_focus,
        'reason': reason,
        'penalties': penalties,
        'scores': all_scores
    }

    st.session_state['all_scores'] = []
    st.session_state['all_states'] = []
    st.session_state['segment_start'] = time.time()

# ===============================
#  ê·¸ë˜í”„ ì‹œê°í™” (matplotlib)
# ===============================
def show_analysis(analysis_data):
    if not analysis_data:
        return 0
    
    st.markdown("---")
    st.header("ğŸ“Š ìµœì¢… ì§‘ì¤‘ë„ ë¶„ì„ ê²°ê³¼")
    
    avg_focus = analysis_data['avg_focus']
    reason = analysis_data['reason']
    penalties = analysis_data['penalties']
    all_scores = analysis_data['scores']

    st.metric(label="í‰ê·  ì§‘ì¤‘ë„ ì ìˆ˜", value=f"{avg_focus:.2f}ì ", delta_color="off")
    st.warning(f"ì£¼ìš” ì§‘ì¤‘ë„ ì €í•˜ ì›ì¸: **{reason}**")

    ## ì‹œê°„ íë¦„ì— ë”°ë¥¸ ì§‘ì¤‘ë„ ê·¸ë˜í”„
    fig1, ax1 = plt.subplots(figsize=(8, 4))
    ax1.plot(range(1, len(all_scores) + 1), all_scores, marker='o', linestyle='-', linewidth=2, color='darkblue')
    ax1.set_title("ì‹œê°„ íë¦„ì— ë”°ë¥¸ ì§‘ì¤‘ë„ ë³€í™”")
    ax1.set_xlabel("ì¸¡ì • êµ¬ê°„ (10ì´ˆ ë‹¨ìœ„)")
    ax1.set_ylabel("ì§‘ì¤‘ë„ ì ìˆ˜")
    ax1.set_ylim(0, 100)
    ax1.grid(True, linestyle='--', alpha=0.7)
    st.pyplot(fig1)

    ## íŒ¨ë„í‹° ë§‰ëŒ€ê·¸ë˜í”„
    labels = list(penalties.keys())
    values = list(penalties.values())
    main_cause = max(penalties, key=penalties.get)
    main_index = labels.index(main_cause)

    fig2, ax2 = plt.subplots(figsize=(8, 5))
    bars = ax2.bar(labels, values, color=['skyblue'] * len(labels))
    bars[main_index].set_color('red') # ì£¼ìš” ì›ì¸ ê°•ì¡°

    # ë§‰ëŒ€ ìœ„ ê°’ í‘œì‹œ
    for i, v in enumerate(values):
        ax2.text(i, v + 0.01, f"{v:.2f}", ha='center', fontsize=10)

    ax2.set_title("ì§‘ì¤‘ë„ íŒ¨ë„í‹° ë¶„ì„")
    ax2.set_xlabel("í–‰ë™ ìš”ì†Œ")
    ax2.set_ylabel("íŒ¨ë„í‹° í¬ê¸°")
    ax2.set_ylim(0, max(values) * 1.2)
    st.pyplot(fig2)



def statistics_start(cap, stop_flag, model):
    with mp_holistic.Holistic(
        static_image_mode=False,
        model_complexity=1,
        refine_face_landmarks=True
    ) as holistic:
        try:
            while not stop_flag.is_set():
                ret, frame = cap.read()
                if not ret:
                    print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                h, w, _ = frame.shape
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = holistic.process(rgb)

                # Streamlit Session Stateì—ì„œ ë³€ìˆ˜ ë¡œë“œ
                blink_count = st.session_state['blink_count']
                yawn_count = st.session_state['yawn_count']
                closed_seconds = st.session_state['closed_seconds']
                half_closed_seconds = st.session_state['half_closed_seconds']
                gaze_out_seconds = st.session_state['gaze_out_seconds']
                eye_closed = st.session_state['eye_closed']
                yawn_state = st.session_state['yawn_state']
                segment_start = st.session_state['segment_start']

                if results.face_landmarks:
                    landmarks = results.face_landmarks.landmark

                    # --- ëˆˆ ê¹œë¹¡ì„ ê³„ì‚° ---
                    left_eye = abs(landmarks[145].y - landmarks[159].y) * h
                    right_eye = abs(landmarks[374].y - landmarks[386].y) * h
                    eye_avg = (left_eye + right_eye) / 2

                    if eye_avg < CLOSED_THRESHOLD:
                        closed_seconds += 1/30.0 # í”„ë ˆì„ë‹¹ ì‹œê°„ ëˆ„ì 
                        if not eye_closed:
                            eye_closed = True
                            blink_count += 1
                    else:
                        eye_closed = False

                    if CLOSED_THRESHOLD <= eye_avg < HALF_CLOSED_THRESHOLD:
                        half_closed_seconds += 1/30.0

                    # --- í•˜í’ˆ ê³„ì‚° ---
                    lip_dist = abs(landmarks[13].y - landmarks[14].y) * h
                    if lip_dist > YAWN_THRESHOLD:
                        if not yawn_state:
                            yawn_state = True
                            yawn_count += 1
                    else:
                        yawn_state = False

                    # --- ì‹œì„  ì´íƒˆ ê³„ì‚° ---
                    left_center = (landmarks[33].x + landmarks[133].x)/2
                    right_center = (landmarks[362].x + landmarks[263].x)/2
                    eye_center_x = (left_center + right_center)/2
                    if not (0.5 - GAZE_THRESHOLD <= eye_center_x <= 0.5 + GAZE_THRESHOLD):
                        gaze_out_seconds += 1/30.0

                # -------------------------------
                # 10ì´ˆ ë‹¨ìœ„ ì§‘ì¤‘ë„ ì˜ˆì¸¡ ë° ë°ì´í„° ëˆ„ì 
                # -------------------------------
                if time.time() - segment_start >= 10:
                    
                    # ğŸ’¡ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„
                    if model is not None:
                        features = np.array([[blink_count, yawn_count, closed_seconds, half_closed_seconds, gaze_out_seconds]])
                        score_pred = model.predict(features)[0]
                    else:
                        # ëª¨ë¸ ì—†ì„ ì‹œ ì„ì‹œ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ ì‚¬ìš©
                        score_pred = calculate_focus(yawn_count, blink_count, closed_seconds, half_closed_seconds, gaze_out_seconds)


                    st.session_state['all_scores'].append(score_pred)
                    st.session_state['all_states'].append({
                        'blink_count': blink_count,
                        'yawn_count': yawn_count,
                        'closed_seconds': closed_seconds,
                        'half_closed_seconds': half_closed_seconds,
                        'gaze_out_seconds': gaze_out_seconds
                    })

                    # ì´ˆê¸°í™”
                    blink_count = yawn_count = closed_seconds = half_closed_seconds = gaze_out_seconds = 0
                    segment_start = time.time()
                
                # Streamlit Session Stateì— ë³€ìˆ˜ ì €ì¥
                st.session_state['blink_count'] = blink_count
                st.session_state['yawn_count'] = yawn_count
                st.session_state['closed_seconds'] = closed_seconds
                st.session_state['half_closed_seconds'] = half_closed_seconds
                st.session_state['gaze_out_seconds'] = gaze_out_seconds
                st.session_state['eye_closed'] = eye_closed
                st.session_state['yawn_state'] = yawn_state
                st.session_state['segment_start'] = segment_start
                
        finally:
            if cap is not None:
                cap.release()
            print("ì¹´ë©”ë¼ ë° ìŠ¤ë ˆë“œ ì¢…ë£Œ.")


st.title("ê³µë¶€ ì§‘ì¤‘ë„ í†µê³„")
st.header("ê³µë¶€ ì§‘ì¤‘ë„ í†µê³„")
st.caption("ìì‹ ì˜ ê³µë¶€ ì‹œê°„ì„ ê¸°ë¡í•˜ê³  ì§‘ì¤‘ë„ í†µê³„ ì‚°ì¶œí•˜ê³  ê³µë¶€ ìŠµê´€ì„ ì ê²€í•´ë³´ì„¸ìš”!")

# 2. ë²„íŠ¼ í´ë¦­ ì‹œ í˜¸ì¶œë  í•¨ìˆ˜ ì •ì˜
def toggle_recording():
    """ë…¹í™” ì‹œì‘/ì¤‘ì§€ ë¡œì§ê³¼ ë¶„ì„ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜"""
    
    # ì¤‘ì§€ ì‹œ, í†µê³„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.
    if st.session_state['recording']:
        # í˜„ì¬ ë…¹í™” ì¤‘ -> ì¤‘ì§€ ë²„íŠ¼ í´ë¦­
        if st.session_state['recording_thread'] is not None and st.session_state['recording_thread'].is_alive():
            st.session_state['stop_flag'].set()
            st.session_state['recording_thread'].join()
            st.session_state['recording_thread'] = None
        
        # ğŸŸ¢ ì¤‘ìš”: í†µê³„ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ (ë…¹í™” ì¢…ë£Œ ì‹œì )
        analysis() 
        
    # ìƒíƒœ ë°˜ì „
    st.session_state['recording'] = not st.session_state['recording']

    # ì‹œì‘ ì‹œ, ì¹´ë©”ë¼ ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    if st.session_state['recording']:
        st.session_state['cap'] = cv2.VideoCapture(0)
        
        if not st.session_state['cap'].isOpened():
            st.error("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.session_state['recording'] = False
            return
        
        st.session_state['stop_flag'].clear()
        st.session_state['recording_thread'] = threading.Thread(
            target=statistics_start, 
            args=(st.session_state['cap'], st.session_state['stop_flag'], st.session_state['model'])
        )
        st.session_state['recording_thread'].start()


# 3. ë²„íŠ¼ í‘œì‹œ
button_label = "í†µê³„ ì¸¡ì • ì¤‘ì§€" if st.session_state['recording'] else "í†µê³„ ì¸¡ì • ì‹œì‘"
st.button(button_label, on_click=toggle_recording)

# 4. ìƒíƒœì— ë”°ë¥¸ í…ìŠ¤íŠ¸ í‘œì‹œ
if st.session_state['recording']:
    st.success("ğŸ”´ ë…¹í™”ì¤‘... (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§‘ì¤‘ë„ ì¸¡ì • ë° ë°ì´í„° ìˆ˜ì§‘ ì¤‘)") 
    
    # ì‹¤ì‹œê°„ ì¸¡ì • ë°ì´í„° í‘œì‹œ (ì„ íƒ ì‚¬í•­)
    st.markdown("---")
    st.subheader("í˜„ì¬ ì¸¡ì • êµ¬ê°„ (10ì´ˆ) ë°ì´í„°")
    col1, col2, col3 = st.columns(3)
    col1.metric("ê¹œë¹¡ì„ ìˆ˜", f"{st.session_state['blink_count']:.0f}")
    col2.metric("í•˜í’ˆ ìˆ˜", f"{st.session_state['yawn_count']:.0f}")
    col3.metric("ëˆˆ ê°ìŒ ì‹œê°„", f"{st.session_state['closed_seconds']:.1f}ì´ˆ")
    st.info(f"ëˆ„ì  ì¸¡ì • êµ¬ê°„: {len(st.session_state['all_scores'])}íšŒ")

else:
    st.info("ì¸¡ì •ì„ ì‹œì‘í•˜ë ¤ë©´ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    # 5. ìµœì¢… ë¶„ì„ ê²°ê³¼ í‘œì‹œ

    show_analysis(st.session_state['analysis'])
